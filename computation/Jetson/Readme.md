# Nvidia Jetson-TX2 as Edge Server
[Jetson-Tx2 Developer Kit](https://developer.nvidia.com/embedded/buy/jetson-tx2-devkit) supports a Linux development environment. 

![Developer Kit](https://github.com/nesl/Heliot/blob/master/docs/images/Tx_2_dev_kit.png)

Next we explain the steps to install the operating system and to setup the Machine learning environment for Tensorflow. After completing the following steps, TX2 can be used to run ML inference using pretrained models in Tensorflow and can be added as an edge device in Heliot framework 

## 1. Installing the operating system
The instructions to install operating system in TX-2 are available officially from Nvidia [here](https://developer.download.nvidia.com/embedded/L4T/r28_Release_v2.0/GA/Docs/Jetson_TX1_and_TX2_Developer_Kits_User_Guide.pdf).

## 2. Setting up the development environment
